import requests
from bs4 import BeautifulSoup
import json

def fetch_article_content(base_url):
    """
    ì£¼ì–´ì§„ URLì—ì„œ ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ê¸°ì‚¬ ë³¸ë¬¸ì„ ë°˜í™˜.
    """
    all_content = []
    page_number = 1

    while True:
        current_url = f"{base_url}.htm" if page_number == 1 else f"{base_url}_{page_number}.htm"

        try:
            response = requests.get(current_url)
            response.raise_for_status()
        except requests.RequestException as e:
            print(f"âŒ í˜ì´ì§€ {page_number} ìš”ì²­ ì˜¤ë¥˜: {e}. í¬ë¡¤ë§ ì¢…ë£Œ.")
            break

        soup = BeautifulSoup(response.text, 'html.parser')

        # ë³¸ë¬¸ì„ í¬í•¨í•  ê°€ëŠ¥ì„±ì´ ìˆëŠ” íƒœê·¸ ì°¾ê¸°
        content_div = soup.find('div', class_='content') or soup.find('span', id='content')

        if not content_div:
            print(f"âš ï¸ í˜ì´ì§€ {page_number}: ë³¸ë¬¸ì„ í¬í•¨í•˜ëŠ” íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. í¬ë¡¤ë§ ì¢…ë£Œ.")
            break

        paragraphs = content_div.find_all('p')
        if not paragraphs:
            print(f"âš ï¸ í˜ì´ì§€ {page_number}: ë³¸ë¬¸ì´ ì—†ìŒ. í¬ë¡¤ë§ ì¢…ë£Œ.")
            break

        # ë¬¸ë‹¨ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        page_content = "\n".join([p.get_text().strip() for p in paragraphs])
        all_content.append(page_content)

        print(f"âœ… í˜ì´ì§€ {page_number} í¬ë¡¤ë§ ì„±ê³µ.")
        page_number += 1

    return "\n\n".join(all_content) if all_content else None

def extract_base_url(link):
    return link.split(".htm")[0] if link else ""

def add_article_content_to_json(json_data):
    for entry in json_data:
        link = entry.get("link")
        if link:
            base_url = extract_base_url(link)
            print(f"ğŸ” ë³¸ë¬¸ ê°€ì ¸ì˜¤ëŠ” ì¤‘: {base_url}")
            article_content = fetch_article_content(base_url)

            # ê¸°ì¡´ 'content'ê°€ ìˆìœ¼ë©´ ìœ ì§€í•˜ê³ , ìƒˆë¡œ í¬ë¡¤ë§í•œ ë³¸ë¬¸ì´ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
            if article_content:
                entry["content"] = article_content
            elif "content" in entry and entry["content"]:
                print(f"ğŸ”„ ê¸°ì¡´ content ìœ ì§€: {entry['content'][:30]}...")  # ê¸°ì¡´ ë³¸ë¬¸ ìœ ì§€ ë¡œê·¸

    return json_data

# JSON íŒŒì¼ ì½ê¸°
input_file = "./output/add_content_xinhuanet3.json"
output_file = "./output/add_content_xinhuanet4.json"

with open(input_file, encoding="utf-8") as file:
    data = json.load(file)

# ë°ì´í„° ì²˜ë¦¬
updated_data = add_article_content_to_json(data)

# ê²°ê³¼ ì €ì¥
with open(output_file, "w", encoding="utf-8") as outfile:
    json.dump(updated_data, outfile, ensure_ascii=False, indent=4)

