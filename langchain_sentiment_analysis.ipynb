{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 임폴트",
   "id": "cd966e8f25fd7891"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:54:18.340291Z",
     "start_time": "2025-02-12T09:54:14.461024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnableLambda"
   ],
   "id": "527758971ab3bc8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 데이터 로드 및 준비",
   "id": "38ce20086db7e3ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T10:22:18.803395Z",
     "start_time": "2025-02-12T10:22:18.765306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# JSON 파일 로드\n",
    "file_path = \"./duplicates.json\"\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 데이터프레임 변환\n",
    "df = pd.DataFrame(data)\n",
    "df = df[['title', 'link', 'date', 'content', 'source']]\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df['quarter'] = df[\"date\"].dt.to_period(\"Q\")\n",
    "\n",
    "# 광고 및 출처 정보 제거 정규식 패턴\n",
    "AD_PATTERNS = [\n",
    "    r\"责任编辑：.*?\",\n",
    "    r\"（本文来源.*?）\",\n",
    "    r\"点击阅读全文.*?\",\n",
    "    r\"来源：.*?\",\n",
    "    r\"更多精彩内容.*?\",\n",
    "    r\"本文转载自.*?\",\n",
    "    r\"欢迎关注我们的.*?\",\n",
    "    r\"广告.*?\",\n",
    "    r\"（.*?记者.*?报道）\",\n",
    "    r\"如需转载请注明.*?\",\n",
    "    r\"查看更多相关信息.*?\"\n",
    "]\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"불필요한 광고 및 출처 제거하고, 구두점 유지\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # 광고 및 출처 제거\n",
    "    for pattern in AD_PATTERNS:\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "\n",
    "    # 특수 문자 및 공백 정리 (단, 구두점 `。！？`는 유지)\n",
    "    text = re.sub(r'[^\\w\\s。！？]', '', text)  # 한자, 숫자, 구두점 외 제거\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # 공백 정리\n",
    "\n",
    "    return text\n",
    "\n",
    "df['input_text'] = df['content'].apply(clean_text)"
   ],
   "id": "24610f5030cb0d1a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### llm 모델설정",
   "id": "a2b484978c52adf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T10:22:30.424749Z",
     "start_time": "2025-02-12T10:22:30.381863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI 모델 설정\n",
    "llm = ChatOpenAI(openai_api_key=api_key, model_name=\"gpt-4-turbo-preview\", temperature=0)\n",
    "\n",
    "# # 메모리 설정 (대화 컨텍스트 유지)\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "#\n",
    "# # 규칙을 메모리에 직접 저장\n",
    "# memory.save_context(\n",
    "#     {\"input_text\": \"이제부터 감성 분석 규칙을 적용합니다.\"},\n",
    "#     {\"response\": \"1. 객관적 사실 전달만 포함된 기사는 0점.\\n\"\n",
    "#                  \"2. 긍정과 부정이 혼재된 경우, 감성 강도에 따라 가중평균을 적용하여 점수를 산정.\\n\"\n",
    "#                  \"3. 감성 점수만 숫자로 출력하고, 설명은 포함하지 않음.\"}\n",
    "# )\n",
    "#\n",
    "# def memory_loader_func(input_data):\n",
    "#     \"\"\"메모리에서 `chat_history`를 추가하면서 `input_text`를 유지\"\"\"\n",
    "#     chat_history = memory.load_memory_variables({})\n",
    "#     chat_history[\"input_text\"] = input_data[\"input_text\"]  # ✅ input_text 유지\n",
    "#     return chat_history\n",
    "#\n",
    "# # 메모리 불러오기\n",
    "# memory_loader = RunnableLambda(memory_loader_func)\n",
    "\n",
    "# 감성 분석 프롬프트 (규칙 포함)\n",
    "basic_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"input_text\"],\n",
    "    template=(\n",
    "        \"다음 기사 본문의 감성을 반드시 **-5에서 +5사이**의 정수로 평가하세요.\\n\"\n",
    "        \"규칙:\\n\"\n",
    "        \"1. 객관적 사실 전달만 포함된 기사는 0점.\\n\"\n",
    "        \"2. 긍정과 부정이 혼재된 경우, 0점을 주지말고 최대한 채점해주세요.\\n\"\n",
    "        \"3. 반드시 숫자만 출력하고, 설명이나 텍스트를 포함하지 마세요.\\n\"\n",
    "        \"기사 본문: {input_text}\\n\"\n",
    "        \"답변:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 기본 프롬프트 체인\n",
    "sentiment_chain = basic_prompt_template | llm"
   ],
   "id": "177ec61c9da5fbdd",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:54:33.354586Z",
     "start_time": "2025-02-12T09:54:33.332645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ✅ 감성 분석 실행 함수\n",
    "def analyze_sentiment(text, max_retries=1):\n",
    "    \"\"\"기사 본문 전체를 감성 분석 (모든 요청에 프롬프트 포함)\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # ✅ 항상 프롬프트 포함하여 OpenAI가 규칙을 유지\n",
    "            formatted_prompt = basic_prompt_template.format(input_text=text)\n",
    "\n",
    "            response = llm.invoke(formatted_prompt)  # ✅ invoke()에 문자열 직접 전달\n",
    "            result_text = response.content.strip()\n",
    "\n",
    "            # ✅ 숫자만 추출 (감성 점수가 아닌 텍스트가 반환될 경우 예외 처리)\n",
    "            match = re.search(r\"-?\\d+\", result_text)\n",
    "            if match:\n",
    "                score = int(match.group())\n",
    "\n",
    "                # ✅ -5 ~ +5 범위 확인 (초과하는 값은 None 반환)\n",
    "                if -5 <= score <= 5:\n",
    "                    return score\n",
    "                else:\n",
    "                    print(f\"⚠️ 범위를 벗어난 감성 점수 ({score}) → 무효 처리\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"⚠️ 숫자 감성 점수 추출 실패: {result_text}\")\n",
    "                return None  # 숫자가 없으면 None 반환\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"⚠️ 오류 발생: {error_msg}, 재시도 {attempt + 1}/{max_retries}\")\n",
    "\n",
    "            # ✅ 429 Rate Limit 오류 감지 (자동 대기 후 재시도)\n",
    "            if \"rate_limit_exceeded\" in error_msg:\n",
    "                try:\n",
    "                    error_json = json.loads(error_msg.split(\" - \")[1])\n",
    "                    wait_time = float(error_json['error']['message'].split(\"Please try again in \")[1].split(\"s\")[0])\n",
    "                    print(f\"⏳ {wait_time}초 후 재시도...\")\n",
    "                    time.sleep(wait_time + 1)\n",
    "                except:\n",
    "                    time.sleep(5)  # 기본 5초 대기\n",
    "            else:\n",
    "                time.sleep(3)  # 일반 오류 시 3초 대기\n",
    "\n",
    "    return None"
   ],
   "id": "b8674bb30309f073",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T10:26:24.947061Z",
     "start_time": "2025-02-12T10:22:45.416276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "backup_file = \"sentiment_analysis_2.csv\"\n",
    "# 기존 df가 이미 존재하는 경우, 백업 파일이 없으면 저장\n",
    "if not os.path.exists(backup_file):\n",
    "    df.to_csv(backup_file, index=False)\n",
    "    print(f\"✅ 백업 파일이 없어서 새로 저장함: {backup_file}\")\n",
    "else:\n",
    "    print(\"✅ 기존 백업 파일이 존재함.\")\n",
    "\n",
    "# 'sentiment_score' 컬럼이 없으면 추가\n",
    "if \"sentiment_score\" not in df.columns:\n",
    "    df[\"sentiment_score\"] = None\n",
    "    print(\"✅ 'sentiment_score' 컬럼 추가함.\")\n",
    "\n",
    "# 감성 분석이 수행되지 않은 행 찾기\n",
    "incomplete_rows = df[df[\"sentiment_score\"].isna()]\n",
    "\n",
    "# 병렬 처리 실행\n",
    "def process_row(index, text):\n",
    "    score = analyze_sentiment(text)\n",
    "    df.at[index, \"sentiment_score\"] = score  # 결과 업데이트\n",
    "    time.sleep(3)  # 각 요청마다 3초 대기 추가 (429 방지)\n",
    "    return index\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    futures = {executor.submit(process_row, idx, row[\"input_text\"]): idx for idx, row in incomplete_rows.iterrows()}\n",
    "\n",
    "    for i, future in enumerate(futures):\n",
    "        future.result()  # 실행 완료 대기\n",
    "        if (i + 1) % 5 == 0:  # 5개 완료될 때마다 저장\n",
    "            df.to_csv(backup_file, index=False)\n",
    "            print(f\"🔄 {i + 1}개 처리 완료, 데이터 저장!\")\n",
    "\n",
    "# 마지막 데이터 저장\n",
    "df.to_csv(backup_file, index=False)\n",
    "print(\"✅ 모든 데이터 처리 완료 및 저장됨!\")"
   ],
   "id": "f1db03c69cc63486",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 백업 파일이 없어서 새로 저장함: sentiment_analysis_2.csv\n",
      "✅ 'sentiment_score' 컬럼 추가함.\n",
      "🔄 5개 처리 완료, 데이터 저장!\n",
      "🔄 10개 처리 완료, 데이터 저장!\n",
      "🔄 15개 처리 완료, 데이터 저장!\n",
      "🔄 20개 처리 완료, 데이터 저장!\n",
      "🔄 25개 처리 완료, 데이터 저장!\n",
      "🔄 30개 처리 완료, 데이터 저장!\n",
      "🔄 35개 처리 완료, 데이터 저장!\n",
      "🔄 40개 처리 완료, 데이터 저장!\n",
      "🔄 45개 처리 완료, 데이터 저장!\n",
      "🔄 50개 처리 완료, 데이터 저장!\n",
      "🔄 55개 처리 완료, 데이터 저장!\n",
      "🔄 60개 처리 완료, 데이터 저장!\n",
      "🔄 65개 처리 완료, 데이터 저장!\n",
      "🔄 70개 처리 완료, 데이터 저장!\n",
      "⚠️ 오류 발생: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-A1JNNlkMXNItEVSFqRa3W3Ch on tokens per min (TPM): Limit 30000, Used 28481, Requested 2018. Please try again in 998ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}, 재시도 1/1\n",
      "🔄 75개 처리 완료, 데이터 저장!\n",
      "🔄 80개 처리 완료, 데이터 저장!\n",
      "⚠️ 오류 발생: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-A1JNNlkMXNItEVSFqRa3W3Ch on tokens per min (TPM): Limit 30000, Used 28436, Requested 2208. Please try again in 1.288s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}, 재시도 1/1\n",
      "🔄 85개 처리 완료, 데이터 저장!\n",
      "🔄 90개 처리 완료, 데이터 저장!\n",
      "🔄 95개 처리 완료, 데이터 저장!\n",
      "🔄 100개 처리 완료, 데이터 저장!\n",
      "✅ 모든 데이터 처리 완료 및 저장됨!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "df3a8db7e42e790f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:54:45.557239Z",
     "start_time": "2025-02-12T09:54:37.911418Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'sentiment_score' 컬럼 추가함.\n",
      "✅ 테스트 데이터 감성 분석 완료! 결과 저장: ./sentiment_analysis_test2.csv\n"
     ]
    }
   ],
   "execution_count": 9,
   "source": [
    "# df 상위 10개 데이터만 사용\n",
    "test_df = df.head(3).copy()\n",
    "\n",
    "# ✅ 'sentiment_score' 컬럼 추가 (없을 경우)\n",
    "if \"sentiment_score\" not in test_df.columns:\n",
    "    test_df[\"sentiment_score\"] = None\n",
    "    print(\"✅ 'sentiment_score' 컬럼 추가함.\")\n",
    "\n",
    "# ✅ 감성 분석이 수행되지 않은 행 찾기\n",
    "incomplete_rows = test_df[test_df[\"sentiment_score\"].isna()]\n",
    "\n",
    "# ✅ 병렬 처리 실행\n",
    "def process_row(index, text):\n",
    "    score = analyze_sentiment(text)\n",
    "    test_df.at[index, \"sentiment_score\"] = score if score is not None else float('nan')  # ✅ NaN 처리\n",
    "    time.sleep(3)  # ✅ 각 요청마다 3초 대기 추가 (429 방지)\n",
    "    return index\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    futures = {executor.submit(process_row, idx, row[\"input_text\"]): idx for idx, row in incomplete_rows.iterrows()}\n",
    "\n",
    "    for i, future in enumerate(futures):\n",
    "        future.result()  # 실행 완료 대기\n",
    "        if (i + 1) % 5 == 0:  # 5개 완료될 때마다 출력\n",
    "            print(f\"🔄 {i + 1}개 처리 완료\")\n",
    "\n",
    "# ✅ 감성 분석 결과 저장\n",
    "test_file = \"./sentiment_analysis_test2.csv\"\n",
    "test_df.to_csv(test_file, index=False)\n",
    "print(f\"✅ 테스트 데이터 감성 분석 완료! 결과 저장: {test_file}\")"
   ],
   "id": "906e5e44a8fef4a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
