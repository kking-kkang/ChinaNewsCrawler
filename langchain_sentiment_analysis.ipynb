{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ì„í´íŠ¸",
   "id": "cd966e8f25fd7891"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:54:18.340291Z",
     "start_time": "2025-02-12T09:54:14.461024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnableLambda"
   ],
   "id": "527758971ab3bc8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„",
   "id": "38ce20086db7e3ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T10:22:18.803395Z",
     "start_time": "2025-02-12T10:22:18.765306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# JSON íŒŒì¼ ë¡œë“œ\n",
    "file_path = \"./duplicates.json\"\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ë³€í™˜\n",
    "df = pd.DataFrame(data)\n",
    "df = df[['title', 'link', 'date', 'content', 'source']]\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df['quarter'] = df[\"date\"].dt.to_period(\"Q\")\n",
    "\n",
    "# ê´‘ê³  ë° ì¶œì²˜ ì •ë³´ ì œê±° ì •ê·œì‹ íŒ¨í„´\n",
    "AD_PATTERNS = [\n",
    "    r\"è´£ä»»ç¼–è¾‘ï¼š.*?\",\n",
    "    r\"ï¼ˆæœ¬æ–‡æ¥æº.*?ï¼‰\",\n",
    "    r\"ç‚¹å‡»é˜…è¯»å…¨æ–‡.*?\",\n",
    "    r\"æ¥æºï¼š.*?\",\n",
    "    r\"æ›´å¤šç²¾å½©å†…å®¹.*?\",\n",
    "    r\"æœ¬æ–‡è½¬è½½è‡ª.*?\",\n",
    "    r\"æ¬¢è¿å…³æ³¨æˆ‘ä»¬çš„.*?\",\n",
    "    r\"å¹¿å‘Š.*?\",\n",
    "    r\"ï¼ˆ.*?è®°è€….*?æŠ¥é“ï¼‰\",\n",
    "    r\"å¦‚éœ€è½¬è½½è¯·æ³¨æ˜.*?\",\n",
    "    r\"æŸ¥çœ‹æ›´å¤šç›¸å…³ä¿¡æ¯.*?\"\n",
    "]\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"ë¶ˆí•„ìš”í•œ ê´‘ê³  ë° ì¶œì²˜ ì œê±°í•˜ê³ , êµ¬ë‘ì  ìœ ì§€\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # ê´‘ê³  ë° ì¶œì²˜ ì œê±°\n",
    "    for pattern in AD_PATTERNS:\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "\n",
    "    # íŠ¹ìˆ˜ ë¬¸ì ë° ê³µë°± ì •ë¦¬ (ë‹¨, êµ¬ë‘ì  `ã€‚ï¼ï¼Ÿ`ëŠ” ìœ ì§€)\n",
    "    text = re.sub(r'[^\\w\\sã€‚ï¼ï¼Ÿ]', '', text)  # í•œì, ìˆ«ì, êµ¬ë‘ì  ì™¸ ì œê±°\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # ê³µë°± ì •ë¦¬\n",
    "\n",
    "    return text\n",
    "\n",
    "df['input_text'] = df['content'].apply(clean_text)"
   ],
   "id": "24610f5030cb0d1a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### llm ëª¨ë¸ì„¤ì •",
   "id": "a2b484978c52adf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T10:22:30.424749Z",
     "start_time": "2025-02-12T10:22:30.381863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "llm = ChatOpenAI(openai_api_key=api_key, model_name=\"gpt-4-turbo-preview\", temperature=0)\n",
    "\n",
    "# # ë©”ëª¨ë¦¬ ì„¤ì • (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€)\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "#\n",
    "# # ê·œì¹™ì„ ë©”ëª¨ë¦¬ì— ì§ì ‘ ì €ì¥\n",
    "# memory.save_context(\n",
    "#     {\"input_text\": \"ì´ì œë¶€í„° ê°ì„± ë¶„ì„ ê·œì¹™ì„ ì ìš©í•©ë‹ˆë‹¤.\"},\n",
    "#     {\"response\": \"1. ê°ê´€ì  ì‚¬ì‹¤ ì „ë‹¬ë§Œ í¬í•¨ëœ ê¸°ì‚¬ëŠ” 0ì .\\n\"\n",
    "#                  \"2. ê¸ì •ê³¼ ë¶€ì •ì´ í˜¼ì¬ëœ ê²½ìš°, ê°ì„± ê°•ë„ì— ë”°ë¼ ê°€ì¤‘í‰ê· ì„ ì ìš©í•˜ì—¬ ì ìˆ˜ë¥¼ ì‚°ì •.\\n\"\n",
    "#                  \"3. ê°ì„± ì ìˆ˜ë§Œ ìˆ«ìë¡œ ì¶œë ¥í•˜ê³ , ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ì•ŠìŒ.\"}\n",
    "# )\n",
    "#\n",
    "# def memory_loader_func(input_data):\n",
    "#     \"\"\"ë©”ëª¨ë¦¬ì—ì„œ `chat_history`ë¥¼ ì¶”ê°€í•˜ë©´ì„œ `input_text`ë¥¼ ìœ ì§€\"\"\"\n",
    "#     chat_history = memory.load_memory_variables({})\n",
    "#     chat_history[\"input_text\"] = input_data[\"input_text\"]  # âœ… input_text ìœ ì§€\n",
    "#     return chat_history\n",
    "#\n",
    "# # ë©”ëª¨ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# memory_loader = RunnableLambda(memory_loader_func)\n",
    "\n",
    "# ê°ì„± ë¶„ì„ í”„ë¡¬í”„íŠ¸ (ê·œì¹™ í¬í•¨)\n",
    "basic_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"input_text\"],\n",
    "    template=(\n",
    "        \"ë‹¤ìŒ ê¸°ì‚¬ ë³¸ë¬¸ì˜ ê°ì„±ì„ ë°˜ë“œì‹œ **-5ì—ì„œ +5ì‚¬ì´**ì˜ ì •ìˆ˜ë¡œ í‰ê°€í•˜ì„¸ìš”.\\n\"\n",
    "        \"ê·œì¹™:\\n\"\n",
    "        \"1. ê°ê´€ì  ì‚¬ì‹¤ ì „ë‹¬ë§Œ í¬í•¨ëœ ê¸°ì‚¬ëŠ” 0ì .\\n\"\n",
    "        \"2. ê¸ì •ê³¼ ë¶€ì •ì´ í˜¼ì¬ëœ ê²½ìš°, 0ì ì„ ì£¼ì§€ë§ê³  ìµœëŒ€í•œ ì±„ì í•´ì£¼ì„¸ìš”.\\n\"\n",
    "        \"3. ë°˜ë“œì‹œ ìˆ«ìë§Œ ì¶œë ¥í•˜ê³ , ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\\n\"\n",
    "        \"ê¸°ì‚¬ ë³¸ë¬¸: {input_text}\\n\"\n",
    "        \"ë‹µë³€:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì²´ì¸\n",
    "sentiment_chain = basic_prompt_template | llm"
   ],
   "id": "177ec61c9da5fbdd",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:54:33.354586Z",
     "start_time": "2025-02-12T09:54:33.332645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# âœ… ê°ì„± ë¶„ì„ ì‹¤í–‰ í•¨ìˆ˜\n",
    "def analyze_sentiment(text, max_retries=1):\n",
    "    \"\"\"ê¸°ì‚¬ ë³¸ë¬¸ ì „ì²´ë¥¼ ê°ì„± ë¶„ì„ (ëª¨ë“  ìš”ì²­ì— í”„ë¡¬í”„íŠ¸ í¬í•¨)\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # âœ… í•­ìƒ í”„ë¡¬í”„íŠ¸ í¬í•¨í•˜ì—¬ OpenAIê°€ ê·œì¹™ì„ ìœ ì§€\n",
    "            formatted_prompt = basic_prompt_template.format(input_text=text)\n",
    "\n",
    "            response = llm.invoke(formatted_prompt)  # âœ… invoke()ì— ë¬¸ìì—´ ì§ì ‘ ì „ë‹¬\n",
    "            result_text = response.content.strip()\n",
    "\n",
    "            # âœ… ìˆ«ìë§Œ ì¶”ì¶œ (ê°ì„± ì ìˆ˜ê°€ ì•„ë‹Œ í…ìŠ¤íŠ¸ê°€ ë°˜í™˜ë  ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬)\n",
    "            match = re.search(r\"-?\\d+\", result_text)\n",
    "            if match:\n",
    "                score = int(match.group())\n",
    "\n",
    "                # âœ… -5 ~ +5 ë²”ìœ„ í™•ì¸ (ì´ˆê³¼í•˜ëŠ” ê°’ì€ None ë°˜í™˜)\n",
    "                if -5 <= score <= 5:\n",
    "                    return score\n",
    "                else:\n",
    "                    print(f\"âš ï¸ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê°ì„± ì ìˆ˜ ({score}) â†’ ë¬´íš¨ ì²˜ë¦¬\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"âš ï¸ ìˆ«ì ê°ì„± ì ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {result_text}\")\n",
    "                return None  # ìˆ«ìê°€ ì—†ìœ¼ë©´ None ë°˜í™˜\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {error_msg}, ì¬ì‹œë„ {attempt + 1}/{max_retries}\")\n",
    "\n",
    "            # âœ… 429 Rate Limit ì˜¤ë¥˜ ê°ì§€ (ìë™ ëŒ€ê¸° í›„ ì¬ì‹œë„)\n",
    "            if \"rate_limit_exceeded\" in error_msg:\n",
    "                try:\n",
    "                    error_json = json.loads(error_msg.split(\" - \")[1])\n",
    "                    wait_time = float(error_json['error']['message'].split(\"Please try again in \")[1].split(\"s\")[0])\n",
    "                    print(f\"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...\")\n",
    "                    time.sleep(wait_time + 1)\n",
    "                except:\n",
    "                    time.sleep(5)  # ê¸°ë³¸ 5ì´ˆ ëŒ€ê¸°\n",
    "            else:\n",
    "                time.sleep(3)  # ì¼ë°˜ ì˜¤ë¥˜ ì‹œ 3ì´ˆ ëŒ€ê¸°\n",
    "\n",
    "    return None"
   ],
   "id": "b8674bb30309f073",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T10:26:24.947061Z",
     "start_time": "2025-02-12T10:22:45.416276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "backup_file = \"sentiment_analysis_2.csv\"\n",
    "# ê¸°ì¡´ dfê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°, ë°±ì—… íŒŒì¼ì´ ì—†ìœ¼ë©´ ì €ì¥\n",
    "if not os.path.exists(backup_file):\n",
    "    df.to_csv(backup_file, index=False)\n",
    "    print(f\"âœ… ë°±ì—… íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ì €ì¥í•¨: {backup_file}\")\n",
    "else:\n",
    "    print(\"âœ… ê¸°ì¡´ ë°±ì—… íŒŒì¼ì´ ì¡´ì¬í•¨.\")\n",
    "\n",
    "# 'sentiment_score' ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€\n",
    "if \"sentiment_score\" not in df.columns:\n",
    "    df[\"sentiment_score\"] = None\n",
    "    print(\"âœ… 'sentiment_score' ì»¬ëŸ¼ ì¶”ê°€í•¨.\")\n",
    "\n",
    "# ê°ì„± ë¶„ì„ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì€ í–‰ ì°¾ê¸°\n",
    "incomplete_rows = df[df[\"sentiment_score\"].isna()]\n",
    "\n",
    "# ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰\n",
    "def process_row(index, text):\n",
    "    score = analyze_sentiment(text)\n",
    "    df.at[index, \"sentiment_score\"] = score  # ê²°ê³¼ ì—…ë°ì´íŠ¸\n",
    "    time.sleep(3)  # ê° ìš”ì²­ë§ˆë‹¤ 3ì´ˆ ëŒ€ê¸° ì¶”ê°€ (429 ë°©ì§€)\n",
    "    return index\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    futures = {executor.submit(process_row, idx, row[\"input_text\"]): idx for idx, row in incomplete_rows.iterrows()}\n",
    "\n",
    "    for i, future in enumerate(futures):\n",
    "        future.result()  # ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸°\n",
    "        if (i + 1) % 5 == 0:  # 5ê°œ ì™„ë£Œë  ë•Œë§ˆë‹¤ ì €ì¥\n",
    "            df.to_csv(backup_file, index=False)\n",
    "            print(f\"ğŸ”„ {i + 1}ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\")\n",
    "\n",
    "# ë§ˆì§€ë§‰ ë°ì´í„° ì €ì¥\n",
    "df.to_csv(backup_file, index=False)\n",
    "print(\"âœ… ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ ë° ì €ì¥ë¨!\")"
   ],
   "id": "f1db03c69cc63486",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°±ì—… íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ì €ì¥í•¨: sentiment_analysis_2.csv\n",
      "âœ… 'sentiment_score' ì»¬ëŸ¼ ì¶”ê°€í•¨.\n",
      "ğŸ”„ 5ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 10ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 15ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 20ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 25ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 30ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 35ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 40ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 45ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 50ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 55ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 60ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 65ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 70ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "âš ï¸ ì˜¤ë¥˜ ë°œìƒ: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-A1JNNlkMXNItEVSFqRa3W3Ch on tokens per min (TPM): Limit 30000, Used 28481, Requested 2018. Please try again in 998ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}, ì¬ì‹œë„ 1/1\n",
      "ğŸ”„ 75ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 80ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "âš ï¸ ì˜¤ë¥˜ ë°œìƒ: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-A1JNNlkMXNItEVSFqRa3W3Ch on tokens per min (TPM): Limit 30000, Used 28436, Requested 2208. Please try again in 1.288s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}, ì¬ì‹œë„ 1/1\n",
      "ğŸ”„ 85ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 90ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 95ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "ğŸ”„ 100ê°œ ì²˜ë¦¬ ì™„ë£Œ, ë°ì´í„° ì €ì¥!\n",
      "âœ… ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ ë° ì €ì¥ë¨!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "df3a8db7e42e790f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T09:54:45.557239Z",
     "start_time": "2025-02-12T09:54:37.911418Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'sentiment_score' ì»¬ëŸ¼ ì¶”ê°€í•¨.\n",
      "âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°ì„± ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: ./sentiment_analysis_test2.csv\n"
     ]
    }
   ],
   "execution_count": 9,
   "source": [
    "# df ìƒìœ„ 10ê°œ ë°ì´í„°ë§Œ ì‚¬ìš©\n",
    "test_df = df.head(3).copy()\n",
    "\n",
    "# âœ… 'sentiment_score' ì»¬ëŸ¼ ì¶”ê°€ (ì—†ì„ ê²½ìš°)\n",
    "if \"sentiment_score\" not in test_df.columns:\n",
    "    test_df[\"sentiment_score\"] = None\n",
    "    print(\"âœ… 'sentiment_score' ì»¬ëŸ¼ ì¶”ê°€í•¨.\")\n",
    "\n",
    "# âœ… ê°ì„± ë¶„ì„ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì€ í–‰ ì°¾ê¸°\n",
    "incomplete_rows = test_df[test_df[\"sentiment_score\"].isna()]\n",
    "\n",
    "# âœ… ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰\n",
    "def process_row(index, text):\n",
    "    score = analyze_sentiment(text)\n",
    "    test_df.at[index, \"sentiment_score\"] = score if score is not None else float('nan')  # âœ… NaN ì²˜ë¦¬\n",
    "    time.sleep(3)  # âœ… ê° ìš”ì²­ë§ˆë‹¤ 3ì´ˆ ëŒ€ê¸° ì¶”ê°€ (429 ë°©ì§€)\n",
    "    return index\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    futures = {executor.submit(process_row, idx, row[\"input_text\"]): idx for idx, row in incomplete_rows.iterrows()}\n",
    "\n",
    "    for i, future in enumerate(futures):\n",
    "        future.result()  # ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸°\n",
    "        if (i + 1) % 5 == 0:  # 5ê°œ ì™„ë£Œë  ë•Œë§ˆë‹¤ ì¶œë ¥\n",
    "            print(f\"ğŸ”„ {i + 1}ê°œ ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "# âœ… ê°ì„± ë¶„ì„ ê²°ê³¼ ì €ì¥\n",
    "test_file = \"./sentiment_analysis_test2.csv\"\n",
    "test_df.to_csv(test_file, index=False)\n",
    "print(f\"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°ì„± ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {test_file}\")"
   ],
   "id": "906e5e44a8fef4a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
